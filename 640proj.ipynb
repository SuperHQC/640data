{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "labels = []\n",
    "with open('Labels.csv') as index:\n",
    "    index = csv.reader(index)\n",
    "    for r in index:\n",
    "        filenames.append(r[0])\n",
    "        labels.append(r[1])\n",
    "        \n",
    "del filenames[0]\n",
    "del labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_hot = []\n",
    "for x in labels:\n",
    "    if x == 'Positive':\n",
    "        labels_hot.append([1,0,0])\n",
    "    if x == 'Neutral':\n",
    "        labels_hot.append([0,1,0])\n",
    "    if x == 'Negative':\n",
    "        labels_hot.append([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./data\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_idx = 0\n",
    "final_label=[]\n",
    "f_idx = 0\n",
    "classfier = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "color = (0,255,0)\n",
    "for file in filenames:\n",
    "    filename = './presidential_videos/' + file\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    count = 0\n",
    "    while(cap.isOpened()):\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        faceRects = classfier.detectMultiScale(gray, scaleFactor=1.5,minNeighbors=8, minSize=(32,32))\n",
    "        \n",
    "        if len(faceRects)>0:\n",
    "            for fr in faceRects:\n",
    "                x,y,w,h = fr\n",
    "#                 cv2.rectangle(frame,(x-20,y-20), (x+w+10,y+h+10), color, 1)\n",
    "                image = frame[y:y+h, x:x+w]\n",
    "                im_name = './data/' + str(f_idx)+'.jpg'\n",
    "                final_label.append(labels_hot[lb_idx])\n",
    "                f_idx += 1\n",
    "                cv2.imwrite(im_name, image)\n",
    "                count += 1\n",
    "#                 cv2.imshow('frame', frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "        if count >= 15:\n",
    "            break\n",
    "    lb_idx += 1\n",
    "#     break\n",
    "# cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14805\n"
     ]
    }
   ],
   "source": [
    "print(len(final_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_size = 64\n",
    "def resize_img(image, height = image_size, width = image_size):\n",
    "    top,bottom, left, right = (0,0,0,0)\n",
    "    \n",
    "    h,w,_=image.shape\n",
    "    \n",
    "    longest_edge = max(h,w)\n",
    "    \n",
    "    if h < longest_edge:\n",
    "        dh = longest_edge - h\n",
    "        top = dh // 2\n",
    "        bottom = dh - top\n",
    "    elif w < longest_edge:\n",
    "        dw = longest_edge - w\n",
    "        left = dw // 2\n",
    "        right = dw - left\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    BLACK = [0,0,0]\n",
    "    constant = cv2.copyMakeBorder(image, top,bottom, left,right, cv2.BORDER_CONSTANT,value = BLACK)\n",
    "    \n",
    "    return cv2.resize(constant, (height,width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14805\n",
      "14805\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "\n",
    "\n",
    "for i in range(len(final_label)):\n",
    "# for i in range(1,2):\n",
    "    img_name = str(i) +'.jpg'\n",
    "    image = cv2.imread('./data/'+img_name)\n",
    "#     cv2.imshow('image', np.array(image,dtype=np.uint8))\n",
    "#     print(image[45,45,1])\n",
    "    if image is None:\n",
    "        del final_label[i]\n",
    "    else:\n",
    "        image = resize_img(image, image_size, image_size)\n",
    "#         cv2.imshow('test', np.array(image,dtype=np.uint8))\n",
    "#         print(image[30,30,1])\n",
    "        images.append(image)\n",
    "#     break\n",
    "        \n",
    "print(len(images))\n",
    "print(len(final_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14805, 64, 64, 3)\n",
      "(14805, 3)\n"
     ]
    }
   ],
   "source": [
    "images = np.array(images, dtype='float')\n",
    "final_label = np.array(final_label)\n",
    "\n",
    "print(images.shape)\n",
    "print(final_label.shape)\n",
    "\n",
    "np.array(final_label)\n",
    "np.savetxt('final_label.csv',final_label, delimiter=',',fmt = '%10.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " ...\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, final_label, test_size = 0.3, random_state = random.randint(0,100))\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if K.image_data_format == 'channel_first':\n",
    "    train_images = train_images.reshape(train_images.shape[0],img_channels, image_size, image_size)\n",
    "    test_images = test_images.reshape(test_images.shape[0],img_channels, image_size, image_size)\n",
    "    input_shape = (img_channels, image_size, image_size)\n",
    "else:\n",
    "    train_images = train_images.reshape(train_images.shape[0], image_size, image_size, img_channels)\n",
    "    test_images = test_images.reshape(test_images.shape[0], image_size, image_size, img_channels)\n",
    "    input_shape = (image_size, image_size, img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10363 train samples\n",
      "4442 test samples\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape[0],'train samples')\n",
    "print(test_images.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images /= 255\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    def build_model(self, input_shape, nb_classes=3):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(32, (3, 3), padding = 'same', input_shape = input_shape))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Conv2D(32, (3, 3)))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "        self.model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Conv2D(64, (3, 3)))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "        self.model.add(Dropout(0.25))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(512))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dropout(0.25))\n",
    "        self.model.add(Dense(nb_classes))\n",
    "        self.model.add(Activation('softmax'))\n",
    "        \n",
    "    def train(self, train_images, train_labels, batch_size = 128, nb_epoch = 15, data_augmentation = True):\n",
    "        self.model.compile(loss = 'categorical_crossentropy', \n",
    "                           optimizer = 'ADAM',\n",
    "                           metrics = ['accuracy'])\n",
    "        if not data_augmentation:\n",
    "            self.model.fit(train_images, \n",
    "                           train_labels, \n",
    "                           batch_size = batch_size,\n",
    "                           epochs = nb_epoch, \n",
    "                           shuffle = True)\n",
    "        else:\n",
    "            datagen = ImageDataGenerator(rotation_range = 20,\n",
    "                                        width_shift_range = 0.2,\n",
    "                                        height_shift_range = 0.2,\n",
    "                                        horizontal_flip = True)\n",
    "            \n",
    "            self.model.fit_generator(datagen.flow(train_images, train_labels, batch_size = batch_size), epochs = nb_epoch)\n",
    "            \n",
    "    def evaluate(self, test_images, test_labels):\n",
    "        score = self.model.evaluate(test_images, test_labels)\n",
    "        print(\"%s:%.3f%%\" % (self.model.metrics_names[1], score[1]*100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_model(input_shape,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "81/81 [==============================] - 62s 771ms/step - loss: 1.0027 - accuracy: 0.5242\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 62s 770ms/step - loss: 0.9570 - accuracy: 0.5491\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 62s 764ms/step - loss: 0.9391 - accuracy: 0.5547\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 62s 769ms/step - loss: 0.9197 - accuracy: 0.5636\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 63s 775ms/step - loss: 0.8965 - accuracy: 0.5783\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 62s 760ms/step - loss: 0.8746 - accuracy: 0.5883\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 61s 758ms/step - loss: 0.8494 - accuracy: 0.6066\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 62s 761ms/step - loss: 0.8225 - accuracy: 0.6182\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 62s 760ms/step - loss: 0.8202 - accuracy: 0.6224\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 62s 760ms/step - loss: 0.8100 - accuracy: 0.6246\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 62s 760ms/step - loss: 0.7815 - accuracy: 0.6442\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 62s 759ms/step - loss: 0.7749 - accuracy: 0.6465\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 61s 758ms/step - loss: 0.7500 - accuracy: 0.6606\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 62s 761ms/step - loss: 0.7345 - accuracy: 0.6672\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 63s 782ms/step - loss: 0.7186 - accuracy: 0.6727\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 63s 776ms/step - loss: 0.7205 - accuracy: 0.6753\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 63s 779ms/step - loss: 0.7113 - accuracy: 0.6779\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 63s 778ms/step - loss: 0.6881 - accuracy: 0.6947\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 63s 772ms/step - loss: 0.6991 - accuracy: 0.6831\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 63s 775ms/step - loss: 0.6701 - accuracy: 0.7020\n"
     ]
    }
   ],
   "source": [
    "model.train(train_images, train_labels, 128,20,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4442/4442 [==============================] - 6s 1ms/step\n",
      "accuracy:72.310%\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
